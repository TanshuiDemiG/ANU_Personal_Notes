# DisMLec20

Created: September 29, 2024 9:11 PM
Class: COMP6005
Reviewed: No

## Discrete Mathematical Models

### Lecture 20: Applications of Bayes’ Theorem and Introduction to Markov Processes

**Lecturer:** Kane Townsend

**Semester:** 2, 2024

---

### Bayes’ Theorem

**Theorem (Bayes’ Theorem):**
For any probability experiment with sample space  S , for any  $n \in \mathbb{N}$ , for any partition $\{B_1, B_2, \ldots, B_n\}$ of  S  and for any event  $A \subseteq S$ , if  $P(A) \neq 0$  and for all  $i \in \{1, 2, \ldots, n\}$  we have  $P(B_i) \neq 0$ , then for all  $k \in \{1, 2, \ldots, n\}$  we have:

$P(B_k|A) = \frac{P(A|B_k)P(B_k)}{\sum_{i=1}^{n}P(A|B_i)P(B_i)}$

**Applications:**

- Solving Monty Hall problem
- Drug testing
- Disease testing
- Defective item rates

**Definitions:**

- **False positive:** A patient tests positive for a disease they do not have.
- **False negative:** A patient tests negative for a disease they do have.

**Example 9.9.3 from Epp:**

- **Scenario:** Medical test for a disease found in 5 people in 1,000.
    - False positive rate: 3%
    - False negative rate: 1%
    - 99% of the time, a person with the condition tests positive.
    - 97% of the time, a person without the condition tests negative.

**Questions:**

1. Probability a randomly chosen person who tests positive actually has the disease.
2. Probability a randomly chosen person who tests negative does not have the disease.

**Solution:**

- Let  A  be the event of testing positive.
- Let  B_1  be the event of having the disease.
- Let  B_2  be the event of not having the disease.

\[ $P(A|B_1) = 0.99, P(A^c|B_1) = 0.01, P(A^c|B_2) = 0.97, P(A|B_2) = 0.03$ \]
\[ $P(B_1) = 0.005, P(B_2) = 0.995$ \]

a. By Bayes’ Theorem:
\[ $P(B_1|A) = \frac{P(A|B_1)P(B_1)}{P(A|B_1)P(B_1) + P(A|B_2)P(B_2)} = \frac{(0.99)(0.005)}{(0.99)(0.005) + (0.03)(0.995)} \approx 0.1422 \approx 14.2\%$ \]

b. By Bayes’ Theorem:
\[ $P(B_2|A^c) = \frac{P(A^c|B_2)P(B_2)}{P(A^c|B_1)P(B_1) + P(A^c|B_2)P(B_2)} = \frac{(0.97)(0.995)}{(0.01)(0.005) + (0.97)(0.995)} \approx 0.999948 \approx 99.995\%$ \]

---

### Markov Processes

马尔可夫过程（Markov Processes）是一种处理系统随时间变化的概率模型。以下是关于马尔可夫过程的一些关键概念：

- **定义：**马尔可夫过程处理系统状态随时间变化的概率。
- **关键概念：**
1. 状态（State）：系统在特定时间点的条件。
2. 转移概率（Transition Probability）：系统在一个时间步内从一个状态转移到另一个状态的概率。
3. 长期行为（Long-term Behavior）：系统经过多个时间步后的可能状态。

马尔可夫过程的一个重要特性是"无记忆性"，即系统在时间n的状态仅取决于时间n-1的状态。

在分析马尔可夫过程时，我们通常使用转移矩阵和状态向量来描述系统的行为。长期来看，许多马尔可夫过程会收敛到一个稳定状态，这可以通过稳态向量来表示。

马尔可夫过程在多个领域都有应用，包括但不限于金融建模、天气预报、语音识别等。

**Introduction:**
Markov processes deal with probabilities of states in a system over time.

**Key Concepts:**

- **State:** The condition of the system at a given time.
- **Transition Probability:** The probability of moving from one state to another in one time-step.
- **Long-term Behavior:** The probable state of the system after many time-steps.

**Example:**

- **Scenario:** Cathy, a freelance computer network consultant, is either employed (E) or unemployed (U) each week.
    - If employed this week, probability of being employed next week: 0.8
    - If unemployed this week, probability of being employed next week: 0.6

**Transition Diagram:**

```
E --> E (0.8)
E --> U (0.2)
U --> E (0.6)
U --> U (0.4)

```

**Transition Matrix:**
 $T = \begin{pmatrix}
0.8 & 0.6 \\
0.2 & 0.4
\end{pmatrix}$ 

这个案例描述了一个马尔可夫过程的例子，具体是关于一位名叫Cathy的自由职业计算机网络顾问的就业状态。案例的主要内容如下：

- Cathy每周的状态可能是就业(E)或失业(U)
- 如果本周就业，下周仍然就业的概率是0.8
- 如果本周失业，下周就业的概率是0.6

这个例子展示了马尔可夫过程的关键特征：

- 有限的状态集（就业和失业）
- 从一个状态到另一个状态的转移概率
- 当前状态只依赖于前一个状态，而不依赖于更早的历史（无记忆性）

案例中还提供了转移图和转移矩阵，这些是描述马尔可夫过程的常用工具。这个例子很好地illustrates了马尔可夫过程的基本概念，并为进一步讨论长期行为和稳态向量铺平了道路。

**State Vectors:**

- **State vector  $x_n$**  shows probabilities of being in each state after  n  time-steps.
- For Cathy:
    - Employed:  $\begin{pmatrix} 1 \\ 0 \end{pmatrix}$
    - Unemployed:  $\begin{pmatrix} 0 \\ 1 \end{pmatrix}$

**Calculations:**

- **One time-step:**
 $x_1 = T x_0 = \begin{pmatrix}
0.8 & 0.6 \\
0.2 & 0.4
\end{pmatrix} \begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} 0.8 \\ 0.2 \end{pmatrix}$
- **Two time-steps:**
$x_2 = T x_1 = \begin{pmatrix}
0.8 & 0.6 \\
0.2 & 0.4
\end{pmatrix} \begin{pmatrix} 0.8 \\ 0.2 \end{pmatrix} = \begin{pmatrix} 0.76 \\ 0.24 \end{pmatrix}$

**Long-term Behavior:**

- For large  n :
 $T^n \approx \begin{pmatrix}
0.75 & 0.75 \\
0.25 & 0.25
\end{pmatrix}$
- **Steady State Vector:**
 $\begin{pmatrix} 0.75 \\ 0.25 \end{pmatrix}$

**Definitions:**

- **Probability Vector:** A vector with non-negative entries that sum to 1.
- **Stochastic Matrix:** A square matrix where all columns are probability vectors.
- **Steady State Vector:** A vector  v  such that  $T v = v$ .

**Theorem (Perron-Frobenius):**

- For a positive stochastic matrix  T , there is a unique normalised steady state vector  v .
- $T^n$  converges to a matrix where each column is  v .

**Properties:**

- **Markov Processes "Have No Memory":**
    - The state at time  n  depends only on the state at time  n-1 .

**Finding Steady State Vectors:**

- One method: Multiply  T  enough times to see convergence.
- Advanced methods: Use linear algebra (covered in the next lecture).

---

This outline provides a structured and detailed overview of the lecture content, making it easier to understand and visualize the key concepts and processes discussed.